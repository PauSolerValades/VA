{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision - P2\n",
    "\n",
    "### **Carefully read the file `README.md` as well as the following instructions before start coding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delivery\n",
    "\n",
    "Up to **1 point out of 10** will be penalized if the following requirements are not fulfilled:\n",
    "\n",
    "- Implemented code should be commented.\n",
    "\n",
    "- The questions introduced in the exercises must be answered.\n",
    "\n",
    "- Comments need to be in **english**.\n",
    "\n",
    "- The deliverable must be a file named **P2_Student1_Student2.zip** that includes:\n",
    "    - The notebook P2_Student1_Student2.ipynb completed with the solutions to the exercises and their corresponding comments.\n",
    "    - All the images used in this notebook.\n",
    "\n",
    "**Deadline (Campus Virtual): October 16th, 23:00 h** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "## Practicum 2: Filtering and edge detection\n",
    "\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main topics are:\n",
    "1. Image smoothing and convolution (exercises 2.1, 2.2, 2.3 and 2.4)\n",
    "2. Edge detection (exercises 2.5, 2.6 and 2.7)\n",
    "\n",
    "In order to complete this practicum, the following concepts need to be understood: linear filters, histograms, convolutions, and edges.\n",
    "\n",
    "The following chapters of the book \"Computer Vision: Algorithms and Applications\" by Richard Szeliski provide additional information:\n",
    "* Chapter 3. Image processing: Point operators & linear filtering.\n",
    "* Chapter 4. Feature detection and matching: Edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 RGB histogram visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Read the image \"face.png\" and visualize the RGB image as well as each of its channels separately (R, G, and B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Visualize the histogram of the image. What is the histogram representing for an image? \n",
    "The plotted histogram must accomplish these requirements (see image bellow as an example of histogram extraction):\n",
    "\n",
    "    - Obtain the histogram with 8 and 32 bins. \n",
    "\n",
    "    - Visualize the histogram of each channel and the gray level image separately and compare them. Comment their differences.\n",
    "\n",
    "Note: What type should be the image in order to compute the histogram? check using different bins for the histogram. \n",
    "\n",
    "Hint : the `exposure` module within the `skimage` library makes the histogram extraction easy!\n",
    "\n",
    "Help: [matplotlib image tutorial](https://matplotlib.org/users/image_tutorial.html)\n",
    "\n",
    "<img src='images_for_notebook/ex21a.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Grayscale and RGB images filtering (convolutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Read the image `face.png` and apply each of the following steps:\n",
    "\n",
    "1. Convert it to grayscale with the function `color.rgb2gray()` of the package `skimage`.\n",
    "2. Convolve it with a horizontal mask `mask_h1d=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]` using the function `ndimage.convolve()` of the package `scipy`.\n",
    "3. Convolve the grayscale image in (1) with a transposed version of the mask in (2).\n",
    "4. Convolve the grayscale image in (1) with a uniform `two-dimensional` mask of dimensions 15x15 with all values set to 1.\n",
    "\n",
    "**Visualize the output of each step (1 to 4) next to each other. Write short titles on each figure to make them understandable.**\n",
    "\n",
    "#### Questions\n",
    "\n",
    "- Observe and comment how the ***type*** and the ***range of values (max & min)*** changed when different operations have been applied on the image. \n",
    "\n",
    "- Is the type of the mask important for the convolution? What effect does each of the masks produce on the original image? Compare the results.\n",
    "\n",
    "Note: Remember that `matplotlib.pyplot` automatically rescales the values of the image before displaying them. Visualize with and without values range rescaling.\n",
    "\n",
    "Note: The command `convolve` performs a multidimensional convolution! A vector should be represented as: [[1,...1]].\n",
    "\n",
    "Note: Remember that before applying the `convolve` function the mask must be normalized (i.e. all values in the mask must sum 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Given a color image (im), what is the difference between ***1*** and ***2*** ?\n",
    "   \n",
    "*** 1. ***\n",
    "\n",
    "im_2=np.array(im, dtype='float')\n",
    "\n",
    "\n",
    "*** 2. ***\n",
    "\n",
    "im_2=np.array(im)\n",
    "\n",
    "\n",
    "im_2=img_as_float(im_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Can we convolve a color (RGB) image? In order to convolve an RGB each of the channels must be convolved separately.\n",
    "\n",
    "Implement a function that applies a 3-channel filter and visualize its result on `face.png` with a 15x15 uniform mask.\n",
    "\n",
    "Which is the result obtained when applying a single-channel filter channel by channel separately?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Effect of image scale on convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Resize an image and observe the variations in the histograms after applying the 15x15 convolution of the previous exercise.\n",
    "\n",
    "1. Reduce it 10 times\n",
    "2. Augment it 10 times. \n",
    "3. Observe if the histogram (i.e. nbins = 32) of the new images changed, and comment what happens and why.\n",
    "\n",
    "Note: Use the command `resize` to change the size of the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Apply a convolution (15x15 uniform mask) on the resized images and compare the results.\n",
    "\n",
    "1. Convolve the original image.\n",
    "2. Convolve the image reduced 10 times.\n",
    "3. Convolve the image augmented 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Image processing with weighting and non-linear filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Generate the following kernels and apply them to the `face.png`:\n",
    "\n",
    "1. Gaussian kernel with sigma = 1\n",
    "2. Gaussian kernel with a different sigma value. Which is the most adequate value for keeping the main objects and structures of the image?\n",
    "3. Median filter.\n",
    "\n",
    "Comment the effect of using different kinds of filters on the original image.\n",
    "\n",
    "Hint: search for the skimage.filters function for creating the different filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) **(Optional)** Apply the smoothing on some other images and present their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Determine the optimal contour \n",
    "\n",
    "a) Load the 'logo.png' image and visualize its contours.\t\n",
    "\n",
    "Apply the different contour extraction tecniques introduced during the theory session and change any parameter if necessary for detecting the edges of the image:\n",
    "\n",
    "1. Roberts.\n",
    "2. Prewitt\n",
    "3. Sobel\n",
    "4. Canny\n",
    "\n",
    "Use subplot and title to visualize the results.\n",
    "\n",
    "#### **Questions**\n",
    "\n",
    "- Which is the best countour detection technique? \n",
    "\n",
    "- Which are the optimal parameters for this image? \n",
    "\n",
    "- Is it necessary to normalize the mask as we do in the filtering applied for the smoothing? \n",
    "\n",
    "**Hint**: use `skimage.feature.canny` for applying the canny filter and `skimage.filters` for the rest.\n",
    "\n",
    "**(Optional)** Superimpose the contours over the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\tRepeat the experiment with other images, you can use the ones included in the folder **images**. Comment if some parameter needs to be changed for the different images.\n",
    "\n",
    "#### **Questions**\n",
    "\n",
    "- Are the contours improved if the image is previously smoothed ? \n",
    "- Which are the limitations of the different images contour extraction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Optional: How many different ways can the Sobel detector be applied? Apply it (in all possible ways), and visualize and compare the obtained results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.6 Applying smoothing in order to obtain hybrid images\n",
    "\n",
    "a) Given `Einstein.jpg` and `monroe.jpg` images:\n",
    "\n",
    "1. Plot both images.\n",
    "2. Apply a low-pass filter to both of them and plot them.\n",
    "3. Apply a high-pass filter to both of them and plot them.\n",
    "\n",
    "By applying smoothing over an image I, we apply a `low-pass` filter. The resulting image can be called L(I). If we substract the filtered one from the original image, we obtain its high frequencies, that we can call H(I), i.e. we apply a `high-pass` filter. \n",
    "\n",
    "***H(I) = I - L(I)***\n",
    "\n",
    "Hint: In order to highlight the effect, in the L(I1) image you should define a lower sigma, while for the H(I1) you should use a higher one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Create hybrid images and visualize them. A hybrid image is obtained by combining the low and high frequencies of the image, i.e. combining the results obtained by the `low-pass` and `high-pass` filters.\n",
    "\n",
    "Hybrid (I1, I2) = L(I1) + H(I2)\n",
    "\n",
    "1. Analyze which is the best way of showing it if our aim is to see Marylin Monroe. \n",
    "2. Additionally, rescale the image to a different size and comment the results. \n",
    "\n",
    "Present the different visualizations of the experiment performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) **(Optional)**\n",
    "\n",
    "Compute hybrid images from other images. Apply it over color images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Anonimization of videos\n",
    "\n",
    "One of the important problems in Computer Vision as a science that manages data (images and videos) is the anonimization of persons appearing in them. Given the collection of images in the folder collectionbigbang, smooth the images in order to make unrecognizible the faces of the persons. Display sequentially the original and the anonimized images.\n",
    "\n",
    "Help: \n",
    "\n",
    "- In order to read all images from a sequence, check the type [ImageCollection](http://scikit-image.org/docs/0.7.0/api/skimage.io.collection.html).\n",
    "\n",
    "- In order to animate a sequence of images, you can use the animation library of matplotlib (in particular, [FuncAnimation](https://matplotlib.org/api/animation_api.html). \n",
    "\n",
    "Note that the animation library does not work with matplotlib inline. You should use the nbagg plugin to visualize the sequence of images. To this purpose, write before animation the following line:\n",
    "% matplotlib nbagg\n",
    "\n",
    "Note: you only need to run and understand the following code, you do not need to implement anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Solution, showing one video per annimation\"\"\"\n",
    "\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "ic = io.ImageCollection('./images/bigbangcollection/*.png')\n",
    "\n",
    "# Rescale to half of their size\n",
    "scale=0.5\n",
    "frames = len(ic)\n",
    "height=np.int((ic[0].shape[0])*scale)\n",
    "width=np.int((ic[0].shape[1])*scale)\n",
    "\n",
    "print('Info about the animation:')\n",
    "print('Num Frames:' + str(frames))\n",
    "print('Images height:' + str(height))\n",
    "print('Images width:' + str(width))\n",
    "\n",
    "# create variable with dimensions of images by the number of frames\n",
    "ic_small=np.ndarray(shape=(height,width,3,frames))\n",
    "\n",
    "# combine them in ic_small variable\n",
    "for i in range(frames):\n",
    "        ic_small[:,:,:,i]=transform.rescale(ic[i],scale)\n",
    "        \n",
    "print('The variable ic_small contains all rescaled images. Its shape is: ' + str(ic_small.shape))\n",
    "\n",
    "\n",
    "%matplotlib nbagg\n",
    "\n",
    "def updatefig1(i): \n",
    "    #im.set_array(ic_small[:,:,:,i]) #showing the small image\n",
    "    im.set_array(conv_color(ic_small[:,:,:,i], mask_2d))   \n",
    "    plt.draw()\n",
    "    return im,\n",
    "\n",
    "fig = plt.figure()\n",
    "im = plt.imshow(ic_small[:,:,:,0])\n",
    "ani = animation.FuncAnimation(fig, updatefig1, interval=2, blit=True, frames=len(ic), repeat= False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Solution, showing 2 videos per annimation : original + blurred\"\"\"\n",
    "\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "ic = io.ImageCollection('./images/bigbangcollection/*.png')\n",
    "\n",
    "# Rescale to half of their size\n",
    "scale=0.5\n",
    "frames = len(ic)\n",
    "height=np.int((ic[0].shape[0])*scale)\n",
    "width=np.int((ic[0].shape[1])*scale)\n",
    "\n",
    "print('Info about the animation:')\n",
    "print('Num Frames:' + str(frames))\n",
    "print('Images height:' + str(height))\n",
    "print('Images width:' + str(width))\n",
    "\n",
    "# create variable with dimensions of images by the number of frames\n",
    "ic_small=np.ndarray(shape=(height,width,3,frames))\n",
    "\n",
    "# combine them in ic_small variable\n",
    "for i in range(frames):\n",
    "        ic_small[:,:,:,i]=transform.rescale(ic[i],scale)\n",
    "        \n",
    "print('The variable ic_small contains all rescaled images. Its shape is: ' + str(ic_small.shape))\n",
    "\n",
    "# \n",
    "# the framesD matrix is created by 0s\n",
    "#\n",
    "%matplotlib nbagg\n",
    "mask_2d=np.ones((7,7)) # 7 by 7 mask with all ones\n",
    "mask_2d/=mask_2d.sum() \n",
    "\n",
    "def updfig2(i):\n",
    "    imm1.set_array(ic_small[:,:,:,i]) # we plot the original image just with the resize\n",
    "    imm2.set_array(conv_color(ic_small[:,:,:,i], mask_2d)) # we plot the convolved image with the mask_2d\n",
    "    plt.draw()\n",
    "    return imm1,imm2,\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(7,3))\n",
    "img0=ic_small[:,:,:,0]\n",
    "imm1=ax1.imshow(img0)\n",
    "imm2=ax2.imshow(img0)\n",
    "plt.show()\n",
    "ani = animation.FuncAnimation(fig, updfig2, interval=2, \n",
    "                              blit=True, repeat=False, frames=len(ic))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
