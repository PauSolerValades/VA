{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "# Practicum 6 - Part 1\n",
    "\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Delivery\n",
    "\n",
    "Up to **1 point out of 10** will be penalized if the following requirements are not fulfilled:\n",
    "\n",
    "- Implemented code should be commented.\n",
    "\n",
    "- The questions introduced in the exercises must be answered.\n",
    "\n",
    "- Add title to the figures to explain what is displayed.\n",
    "\n",
    "- Comments need to be in **english**.\n",
    "\n",
    "- The deliverable must be a file named **P6_Student1_Student2.zip** that includes:\n",
    "    - The notebook P6_Student1_Student2.ipynb completed with the solutions to the exercises and their corresponding comments.\n",
    "    - All the images used in this notebook.\n",
    "\n",
    "**Deadline (Group A- Group F): December 10th, 23:00 h**\n",
    "\n",
    "**Deadline (Group B): December 11th, 23:00 h**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "## Haar-like features applied for face detection\n",
    "==============================================================================================\n",
    "\n",
    "Today's exercices will practise the following:\n",
    "\n",
    "- Integral images and a classical use for fast harr-like feature computation.\n",
    "- Use of Adaboost for classification.\n",
    "- Decisions based on a user-defined threshold for balancing precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "from time import time\n",
    "\n",
    "import skimage\n",
    "from skimage.feature import haar_like_feature\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import haar_like_feature_coord\n",
    "from skimage.feature import draw_haar_like_feature\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar-like feature descriptor for face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Haar-like feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haar-like features are features extracted from the images to recognize objects. These features are normally used in face recognition. The key to face recognition is to detect the relevant features of humans such as eyes, lips, or nose. \n",
    "\n",
    "\n",
    "<img src=\"notebook_images/haar-like.png\" width=400, height=400>\n",
    "\n",
    "Try to guess where in the face image we expect to detect an edge, line or another facial feature and what would be the most appropriate Haar-feature for them? \n",
    "\n",
    "<img src=\"notebook_images/haar-like1.png\" width=500, height=500>\n",
    "\n",
    "\n",
    "A real application would be:\n",
    "\n",
    "<img src=\"notebook_images/face.png\" width=300, height=300>\n",
    "\n",
    "\n",
    "To describe the face, we can apply convolutions with Haar features. What alternative to the convolution with Haar-features, do you know?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face detection\n",
    "\n",
    "Haar-like feature descriptors were successfully used to implement the first real-time face detector. In this laboratory we will see an example illustrating the extraction, selection, and classification of Haar-like features to detect faces vs. non-faces.\n",
    "\n",
    "Documentation [Haar-like feature skimage](https://scikit-image.org/docs/0.14.x/auto_examples/xx_applications/plot_haar_extraction_selection_classification.html)\n",
    "\n",
    "\n",
    "In this work we are going to see:\n",
    "\n",
    "\n",
    "1. What is a Haar-like feature?\n",
    "2. Build Integral image\n",
    "3. Extract Haar features\n",
    "4. The Adaboost Classifier\n",
    "5. Face detection with cascade classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Building integral image\n",
    "\n",
    "Compute all the Haar-like features (we can define up to 16000 million masks), can be a slow process. To compute it faster, we are going to use the integral images (instead of convolutions). It is very useful because we are able to save all the sums and substrations of image rectangles to avoid computing all the features every time.\n",
    "\n",
    "When creating an Integral Image, we need to create a Summed Area Table. What does represent any point (x,y) in this table?\n",
    "\n",
    "<img src=\"notebook_images/integral_image.png\" width=250, height=2500>\n",
    "\n",
    "An example :\n",
    "\n",
    "<img src=\"notebook_images/integral_image1.png\" width=400, height=400>\n",
    "\n",
    "To easy the computation of Haar features, the integral image must have an additional row and column full of zeros (first row and first column). Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Build a function `to_integral_image` that computes the integral image of an input (2D) array.\n",
    "\n",
    "The integral image must have an additional row and column full of zeros (first row and first column).\n",
    "Make sure that the values of the integral image are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_integral_image(img_arr):\n",
    "    row_sum = np.zeros(img_arr.shape)\n",
    "    integral_image_arr = np.zeros((img_arr.shape[0] + 1, img_arr.shape[1] + 1))\n",
    "\n",
    "    # <your solution>\n",
    "    \n",
    "    return integral_image_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Construct a binary image of dimensiones 5x5 and visualize it together with its integral image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = ...\n",
    "ii_img_array = to_integral_image( img_array )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** Integral image test\n",
    "\n",
    "To make sure that the values of the integral image are correct, compute the following tests:\n",
    "\n",
    " - `sum(img_array) == ii_img_array[-1,-1]`\n",
    " - `img_array[0,:].sum() == ii_img_array[1,-1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4** Let's check in real images.\n",
    "\n",
    "Choose an image from the directory ``./faces``, visualize both the original and the integral image, and make the same test that in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5** What do the following lines mean? How can you explain this?\n",
    "\n",
    " - `sum(img_array) == ii_img_array[-1,-1]`\n",
    " - `img_array[0,:].sum() == ii_img_array[1,-1]`\n",
    " - `ii_img_array[0,-1].sum() == 0`\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6: (Optional)** Alternatively to your own function, you can use the function of skimage ``skimage.transform import integral_image``. \n",
    "\n",
    "Compare the result obtained using your funtion and that obtained using the function provided by skimage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Haar-like features\n",
    "\n",
    "Let's use the haar_like_feature function from skimage [Haar like feature](https://scikit-image.org/docs/0.14.x/api/skimage.feature.html#skimage.feature.haar_like_feature)\n",
    "\n",
    "*skimage.feature.haar_like_feature(int_image, rint, cint, widthint, heightint, feature_type=None, feature_coord=None)*\n",
    "\n",
    "Check the parameters and the returned value of the ``function haar_like_feature()`` before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Extract features\n",
    "\n",
    "**2.1** Once we have the function to get the integral image, we can extract the features before building the classifier.\n",
    "\n",
    "Define a function ``extract_feature_image`` to obtain the Haar-like features, using a given type of features ``feature_types``, from an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = ['type-2-x', 'type-2-y',\n",
    "                 'type-3-x', 'type-3-y',\n",
    "                 'type-4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_image(image, feature_type, feature_coord=None):\n",
    "    features = []\n",
    "    \n",
    "    # Your solution here\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your function using the choosing image from *1.4*. \n",
    "\n",
    "**Note:** You have to obtain a feature vector. Print the vector shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extract_feature_image(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** Plot a Haar-like feature on an image:\n",
    "\n",
    "To visualize Haar-like features on an image, we need the fuctions, provided by skimage, ``haar_like_feature_coord()``, which computes the coordinates of Haar-like features, and ``draw_haar_like_feature()``, used to visualize that features.\n",
    "\n",
    "Before continuing, please, **check the online documentation of the two functions**\n",
    "\n",
    "- *skimage.feature.haar_like_feature_coord(width, height, feature_type=None)*\n",
    "\n",
    "- *skimage.feature.draw_haar_like_feature(image, r, c, width, height, feature_coord, color_positive_block=(1.0, 0.0, 0.0), color_negative_block=(0.0, 1.0, 0.0), alpha=0.5, max_n_features=None, random_state=None)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function ``plotFeatures``  to visualize Haar-like features on an images, given a array of feature types ``feature_types``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your function using the choosing image from *1.4* as follows:\n",
    "<img src=\"notebook_images/image1.png\" width=600, height=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFeatures(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Preparing the Dataset\n",
    "\n",
    "**3.1** Read all the images from the directories ``./faces`` and ``./nonfaces`` and build an array with the all the features. \n",
    "\n",
    "Futhermore, build the class labels vector ``y`` with the label of all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a vector with the faces features\n",
    "path = \"./faces/\"                       \n",
    "face_images = [skimage.io.imread(path + f) for f in os.listdir(path)]\n",
    "\n",
    "features_faces = []\n",
    "\n",
    "# your solution here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a vector with the non-faces features\n",
    "path = \"./nonfaces/\"                       \n",
    "non_face_images = [skimage.io.imread(path + f) for f in os.listdir(path)]\n",
    "\n",
    "non_features_faces = []\n",
    "\n",
    "# your solution here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features_faces + non_features_faces)\n",
    "y = np.array(...) # Labels face = 1, non face = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2** Using the function ``train_test_split`` from sklearn, divide the dataset into *train* and *test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4  Adaboost training\n",
    "\n",
    "**4.1** Train an Adaboost classifier using:\n",
    "\n",
    "*class sklearn.ensemble.AdaBoostClassifier(n_estimators=50, learning_rate=1.0)*\n",
    "\n",
    "What is an Adaboost doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2** Evaluate the accuracy of the Adaboost classifier using the *predict* and *score* methods of the classifier. What are these methods doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the parameter ``n_estimators`` and see what happens. Does it improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3** The method ``feature_importances_`` of the Adaboost is giving the importance of the features. Implement a function to visualize the 10 most important features on an image of a face on your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4**  Try the Adabost classifier using other faces and non-faces images. What is the result? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.5 (Optional)** Implement the Adaboost training the model with just 1 type of feature. And 2 types? And 3 types? Plot the results comparing the precision. Draw conclusions about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Cascade of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cascade Adaboost is implemented in the class ``skimage.feature.Cascade``.\n",
    "\n",
    "**5.1** Compare the performance of the Cascade classifier  and your Adaboost classifier from point 4 on the folder *another_faces*. Show the detected faces by both classifiers and compare their score.\n",
    "\n",
    "<img src=\"notebook_images/cascade.png\" width=300, height=300>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import Cascade\n",
    "from skimage import data\n",
    "from matplotlib import patches\n",
    "\n",
    "# Load face images\n",
    "path = \"./another_faces/\"                       \n",
    "original_another_faces = [skimage.io.imread(path + f) for f in os.listdir(path)]\n",
    "\n",
    "# Load the Cascade trained file from the module root.\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialize the dectector cascade\n",
    "query = original_another_faces[1]\n",
    "detector = Cascade(trained_file)\n",
    "detected = detector.detect_multi_scale(img=query, scale_factor=1.2, step_ratio=1, min_size=(50, 50),\n",
    "                                       max_size=(500, 500))\n",
    "\n",
    "plt.imshow(query)\n",
    "img_desc = plt.gca()\n",
    "plt.set_cmap('gray')\n",
    "\n",
    "for patch in detected:\n",
    "\n",
    "    img_desc.add_patch(\n",
    "        patches.Rectangle(\n",
    "            (patch['c'], patch['r']),\n",
    "            patch['width'],\n",
    "            patch['height'],\n",
    "            fill=False,\n",
    "            color='r',\n",
    "            linewidth=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
