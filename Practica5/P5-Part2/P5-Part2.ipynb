{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "# Practicum 5 - Part 2\n",
    "\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Delivery\n",
    "\n",
    "Up to **1 point out of 10** will be penalized if the following requirements are not fulfilled:\n",
    "\n",
    "- Implemented code should be commented.\n",
    "\n",
    "- The questions introduced in the exercises must be answered.\n",
    "\n",
    "- Add title to the figures to explain what is displayed.\n",
    "\n",
    "- Comments need to be in **english**.\n",
    "\n",
    "- The deliverable must be a file named **P5_Student1_Student2.zip** that includes:\n",
    "    - The notebook P5_Student1_Student2.ipynb completed with the solutions to the exercises and their corresponding comments.\n",
    "\n",
    "**Deadline (Group A- Group F): November 30th, 23:00 h**\n",
    "\n",
    "**Deadline (Group B): November 1st, 23:00 h**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "##  Image search using textures\n",
    "==============================================================================================\n",
    "\n",
    "#### Problem we want to solve\n",
    "- Given a query image **$x$** and a set of images **$X$** we would like to retreive the most similar to **$x$** images from  **$X$**.\n",
    "\n",
    "The exercises of this notebook will show how we can perform image similarity search using:\n",
    "\n",
    "**Part 1:**\n",
    "\n",
    "- Gaussian filters\n",
    "- Descriptors based on texture \n",
    "\n",
    "**Part 2:**\n",
    "\n",
    "- Distance between images and similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import filters\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "from skimage.transform import resize\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import joblib  ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Import previous functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leung-Malik (LM) Filter Bank\n",
    "We can apply a collection of multiple filters that we call a filter bank. Note that if we apply $D$ filters our feature vectors will be $D$ dimensional.\n",
    "\n",
    "The following image shows a filter bank. In the filter bank we typically want filters to capture a combination of scales, orientations of different types of patterns. This particular filter bank is The Leung-Malik (LM) Filter Bank.\n",
    "\n",
    "<img src=\"./images_notebook/filter_bank.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import Leung-Malik filters as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import LM_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter_bank = LM_filters.makeLMfilters()\n",
    "filter_bank.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_filters = filter_bank.shape[-1]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=12, nrows=4, figsize=(15,3))\n",
    "\n",
    "k = 0\n",
    "for i in range(4):\n",
    "    for j in range(12):\n",
    "        ax[i,j].imshow(filter_bank[:,:,k], cmap = 'gray')\n",
    "        ax[i,j].axis(\"off\")\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import functions\n",
    "\n",
    "We need to use `extract_features()` and  `get_dataset_features()` from **Practicum 5 - Part 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the one hand, function `extract_features(image, filter_bank, n_filters)` returns a feature vector of shape `n_filters`, from the filter bank, using a  single image `image`\n",
    "\n",
    "$$\n",
    "\\text{feat}(x) = \\left( \\text{mean}( |r_1|), \\dots,\\text{mean}(|r_D|) \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image, filter_bank, n_filters):\n",
    "   features = np.zeros(n_filters)\n",
    "   \n",
    "   ## Complete this function\n",
    " \n",
    "   return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, function `get_dataset_features(all_images, filter_bank)`, that applies `extract_features()`, returns a matrix containing the feature vectors for all the images in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_features(all_images,  filter_bank):\n",
    "   n_images = ...\n",
    "   n_filters = ...\n",
    "   feature_vectors=np.zeros((n_images,n_filters))\n",
    " \n",
    "   ## Complete this function\n",
    "   \n",
    "   return feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint: Please, check all the functions are well working before continuing!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & resize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Similarly to **Practicum 5 - Part 1**, read all the images in the directories, **resized them to 250x250 pixels** and save the image in an array:\n",
    "\n",
    "<ul>\n",
    "    <li>./images/pizza/</li>\n",
    "    <li>./images/flowers/</li>\n",
    "    <li>./images/pets/</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "pizza_images = ...\n",
    "flowers_images = ...\n",
    "pets_images = .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try the function\n",
    "all_images = pizza_images + flowers_images + pets_images\n",
    "feature_vectors=get_dataset_features(all_images,  filter_bank, n_filters=filter_bank.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2 Retrieving the most similar images\n",
    "\n",
    "\n",
    "## Similarity search\n",
    "\n",
    "Let us assume $f(x) \\in \\mathbb{R}^D$ represents a set of features for $x$. Given a query image $x$ and another image $x^m$ from the database, we can compute the distance between images as\n",
    "$$\n",
    "\\text{distance}\\left( f(x) , \\, f(x^m) \\right) = \\| \\text{feat}(x)  - \\text{feat}(x^m)  \\|_2 =  \\sqrt{ \\sum_{d=1}^\\text{D} \\left( f(x)_d - f(x^m)_d  \\right)^2 }\n",
    "$$\n",
    "\n",
    "then we can find the closest image $x^{m^*}$ from the database to $x$ as $m^* =  \\text{argmin}_{m} \\{ \\| \\text{feat}(x)  - \\text{feat}(x^m)  \\|_2 \\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**3.2** Implement a function `retrieve_images(im, all_images, filter_bank, k=5)` to retrieve and visualize the `k` most similar images (according to the l2 norm) to `im` and the corresponding distances.\n",
    "\n",
    "The input of this function need to be the images of interest `im`, the whole data set `all_images`, the filter bank and an integer value `k`, which defines the number of images to be shown.\n",
    "\n",
    "The function should return the ordered vector of distances.\n",
    "\n",
    "<img src=\"./images/indice.png\" >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_images(im, all_images, filter_bank, k=5):   \n",
    "    distances = ...\n",
    "    closest = ...\n",
    "    \n",
    "    ## Complete this function\n",
    "\n",
    "    return closest, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your function using ``/images/pizza.jpg``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your function\n",
    "pizza = imread('./images/pizza.jpg')\n",
    "closest, distances = retrieve_images( pizza, all_images, filter_bank, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Plot the ordered distance vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3** Try your function using a different number of closest images `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4** (Optional) Try your function using ``/images/dog.jpg``, and ``/images/flower.jpg``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the accuracy of the algorithm: given a query image. \n",
    "\n",
    "**3.5** Implement a function `accuracy(feature_vectors, class_labels, im_features, class_im,  k=5)`, which takes as input `feature_vectors`, the `class_labels` for the images (`0 = pizza`, `1 = flower` and `2 = pet`), the number of images to retrieve `k`, a query image (i.e. the feature vector for the image of interest) and the class of the query image `class_im`. \n",
    "\n",
    "Returns as output the number of retrieved images that belong to class `class_im` divided by the total of images retrieved `k` (this is the accuracy).\n",
    "\n",
    "**Hint**: Be careful to exclude the query image from the retrieved images (i.e. those cases in which `distance=0.0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_labels = np.concatenate((np.zeros(30), np.ones(30),  2*np.ones(30))).reshape(90,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def accuracy(feature_vectors, class_labels, im_features, class_im, k=5):\n",
    "    \n",
    "    ## Complete this function\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your function\n",
    "im_features = extract_features(...)\n",
    "print(\"acc: \", accuracy(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy with k=10 with the previous images. Does the accuracy match the images retrieved from the previous exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.6** Modify (if necessary) functions `extract_features()` and `get_dataset_features()` in order to use only a given number of filters. Compute the accuracy using `n_filters=6`, `n_filters=18` and `n_filters=36`. \n",
    "\n",
    "Comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.7** (Optional) Try your function using other images and modifying the number of filters to be used.\n",
    "\n",
    "**Hint:** You can use `im_features = feature_vectors[j]` and `class_im = class_labels[j]`, for a given `j` value, in order to simplify the problem, instead of recomputing the features for a new image. **Remember** to exclude the query image from the retrieved images!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Image retrieval based on texture and color. \n",
    "\n",
    "**3.8** Make a function ` lm_features_rgb`  that returns the features based on a color descriptor. \n",
    "\n",
    "**Hint:** How will you define it? What should be the dimensonality of the new descriptor?.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lm_features_rgb(image):\n",
    "        \n",
    "    ## Complete this function\n",
    "\n",
    "    return features_for_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try your function\n",
    "lm_rgb_features = lm_features_rgb(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Apply the function to all the images in the dataset\n",
    "\n",
    "**3.9** Using ` lm_features_rgb` build the features of all the datapoints in and save them in `X_lm_rgb`.\n",
    "\n",
    "**Hint:** You can parallelize the feature building process using `joblib.Parallel`. This will make the computation much faster if you have a processor with more than two threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "X_lm_rgb = joblib.Parallel(n_jobs=8)(joblib.delayed(lm_features_rgb)(im) for im in all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the accuracy of the method using lm rgb features\n",
    "\n",
    "**3.10** Compute the accuracy of the retrieved images using the features that contain color information. Make a plot of the 4 closest images to the query images in the `lm_rgb` space.\n",
    "\n",
    "Is the accuracy higher? Please, comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the accuracy of the method using a) texture, b) color and c) texture + color  features\n",
    "\n",
    "**3.10** Compute the accuracy of the retrieved images using the features that contain color information. Make a plot of the 4 closest images to the query images in the `lm_rgb` space.\n",
    "\n",
    "Is the accuracy higher? Please, comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**3.11** Compute the accuracy of the retrieved images using the features that contain texture and color information. Make a plot of the 4 closest images to the query images in the `lm_rgb_texture` space.\n",
    "\n",
    "Is the accuracy higher? Please, comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
